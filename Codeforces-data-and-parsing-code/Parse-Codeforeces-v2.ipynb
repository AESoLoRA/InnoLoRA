{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2dLE41xBQW9",
        "outputId": "a27e3d99-b9a8-4531-8b62-178b72397158"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ew3GRK2NSX6",
        "outputId": "55eccb9a-2ef4-4d4c-822d-6228596303c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.10.0-py3-none-any.whl (6.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/6.7 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m4.8/6.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.16)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.1-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "H4VRg0ugNVR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install chromium chromium-driver"
      ],
      "metadata": {
        "id": "vlEHhSlMNXwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5q8SSWraNbHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXH4Vqs0mKJh"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "Main_Languages = ['Haskell']\n",
        "timeout_seconds = 4\n",
        "timeout_seconds1 = 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "problems = pd.read_csv('problems.csv',header=0)"
      ],
      "metadata": {
        "id": "7E5sZSMP_XON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f\"/page/{Page_number}?order=BY_PROGRAM_LENGTH_ASC\""
      ],
      "metadata": {
        "id": "B3GxLTrxDhT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def link_generator(problems):\n",
        "  Links=[]\n",
        "  for i, problem in problems.iterrows():\n",
        "    contest_id = problem['contest_id']\n",
        "    index = problem['index']\n",
        "    Link_to_status = f\"https://codeforces.com/problemset/status/{contest_id}/problem/{index}\"\n",
        "    Link_to_problem = f\"https://codeforces.com/problemset/problem/{contest_id}/{index}\"\n",
        "    Links.append((Link_to_problem,Link_to_status))\n",
        "  return Links\n",
        "Links = link_generator(problems)"
      ],
      "metadata": {
        "id": "x2KqLEkQxHCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Links[13]"
      ],
      "metadata": {
        "id": "a_CKuFkEBxxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Links)"
      ],
      "metadata": {
        "id": "075tV2649bCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_links_ids_from_status_page(soup , LINK):\n",
        "  \"\"\"\n",
        "  https://codeforces.com/problemset/status/1370/problem/D/page/1?order=BY_PROGRAM_LENGTH_ASC\n",
        "  status page of one problem contain multible solutions\n",
        "  I exctracted the solutions link and submissions id  that has language in MainLanguage list\n",
        "  \"\"\"\n",
        "  table_of_submissions = soup.find('table', class_='status-frame-datatable')\n",
        "\n",
        "  i=0\n",
        "  Links_Ids = []\n",
        "\n",
        "  if table_of_submissions == None:\n",
        "    print(f\"no table of submission in {LINK}\")\n",
        "    return Links_Ids\n",
        "  try:\n",
        "    #Access submission table\n",
        "    for row in table_of_submissions.find_all('tr'):\n",
        "      #Access cells in submission table\n",
        "      cells = row.find_all('td')\n",
        "\n",
        "      if len(cells) == 0:\n",
        "        continue\n",
        "      #Access Lang cell\n",
        "      if len(cells) >= 5:\n",
        "        language = cells[4].text.strip()\n",
        "        if language not in Main_Languages:\n",
        "          continue\n",
        "\n",
        "      #Access \"#\" Cell\n",
        "        first_cell = cells[0]\n",
        "        a_tag = first_cell.find('a', class_='view-source')\n",
        "\n",
        "        if a_tag:\n",
        "          Link_to_source_solution = a_tag['href']\n",
        "          submission_id = a_tag['submissionid']\n",
        "          Links_Ids.append((\"https://codeforces.com\" + Link_to_source_solution , submission_id))\n",
        "        else:\n",
        "          print(f\"Error2 - There is no a_Tag {LINK}\\n\")\n",
        "      else:\n",
        "        print(f\"Error1 - There is no language value in this row {LINK}\\n\")\n",
        "      i+=1\n",
        "  except Exception as e:\n",
        "      traceback.print_exc()\n",
        "  return Links_Ids"
      ],
      "metadata": {
        "id": "8K3thuSxEzvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920, 1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver"
      ],
      "metadata": {
        "id": "jzv1tAmcNvmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"URL = \"https://codeforces.com/problemset/status/950/problem/B\"\n",
        "driver = web_driver()\n",
        "driver.get(URL)\n",
        "\n",
        "dropdown = driver.find_element(By.XPATH, \"//select[@id='programTypeForInvoker']\")\n",
        "option = dropdown.find_element(By.XPATH, \"//option[@value='cpp.g++17']\")\n",
        "option.click()\n",
        "\n",
        "dropdown1 = driver.find_element(By.XPATH, \"//select[@id='verdictName']\")\n",
        "option1 = dropdown1.find_element(By.XPATH, \"//option[@value='WRONG_ANSWER']\")\n",
        "option1.click()\n",
        "\n",
        "button = driver.find_element(By.XPATH, \"//input[@type='submit' and @value='Apply']\")  # Locate the button using XPath\n",
        "button.click()\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3y9IPGkd3BT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#URL = \"https://codeforces.com/contest/4/status/A\"\n",
        "\n",
        "#page = requests.get(URL)\n",
        "\n",
        "def extract_submissions_links_from_all_status( URL):\n",
        "  try:\n",
        "    driver = web_driver()\n",
        "    driver.get(URL)\n",
        "\n",
        "    dropdown = driver.find_element(By.XPATH, \"//select[@id='programTypeForInvoker']\")\n",
        "    option = dropdown.find_element(By.XPATH, \"//option[@value='haskell.ghc']\")\n",
        "    option.click()\n",
        "\n",
        "    dropdown1 = driver.find_element(By.XPATH, \"//select[@id='verdictName']\")\n",
        "    option1 = dropdown1.find_element(By.XPATH, \"//option[@value='OK']\")\n",
        "    option1.click()\n",
        "\n",
        "    button = driver.find_element(By.XPATH, \"//input[@type='submit' and @value='Apply']\")  # Locate the button using XPath\n",
        "    button.click()\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "    extracted_data=[]\n",
        "    try:\n",
        "      extracted_data.extend(extract_links_ids_from_status_page(soup, URL))\n",
        "    except:\n",
        "      print(f\"Error - in exctracting submissions_links_from_all_status: {URL}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error - in driver {URL} \")\n",
        "    traceback.print_exc()\n",
        "  return extracted_data\n",
        "  \"\"\"pagination_div = soup.find_all('div', class_=\"pagination\")[-1]\n",
        "  last_page_number = -1\n",
        "  if pagination_div:\n",
        "    ul_element = pagination_div.find('ul')\n",
        "    if ul_element:\n",
        "      last_page_number = ul_element.find_all('li')[-2].text.strip()\n",
        "    else:\n",
        "      print(\"Error - no <ul>\\n\")\n",
        "      print(link)\n",
        "  else:\n",
        "    print(\"Error - no <li>\\n\")\n",
        "\n",
        "  print(last_page_number,f\" last page number for {link}\\n\")\n",
        "\n",
        "  if last_page_number == -1:\n",
        "    last_page_number = 10\n",
        "\n",
        "  for page_number in range(1,int(last_page_number)+1):\n",
        "    URL_pages = link +  f\"/page/{page_number}?order=BY_PROGRAM_LENGTH_ASC\"\n",
        "    try:\n",
        "      other_page = requests.get(URL_pages , timeout=timeout_seconds)\n",
        "      if other_page.status_code != 200:\n",
        "        print(f\"Error - could not access to status page num: {URL_pages}\")\n",
        "        continue\n",
        "      other_soup = BeautifulSoup(other_page.content, \"html.parser\")\n",
        "      extracted_data.extend(extract_links_ids_from_status_page(other_soup, URL_pages))\n",
        "      #print(len(extracted_data) , page_number)\n",
        "    except:\n",
        "      print(f\"Error - could not access to status page num: {URL_pages}\")\n",
        "      pass\n",
        "  return extracted_data\n",
        "  \"\"\"\n",
        "#ex = extract_submissions_links_from_all_status(URL)\n",
        "#ex"
      ],
      "metadata": {
        "id": "dxOd31xHGVEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Link1= \"https://codeforces.com/problemset/submission/1370/84700462\"\n",
        "#page = requests.get(Link1)\n",
        "#print(page.status_code)\n",
        "#soup = BeautifulSoup(page.content, 'html.parser')\n",
        "def extract_code_from_submission(soup , LINK):\n",
        "  try:\n",
        "    code = soup.find('pre', id='program-source-text').text.strip()\n",
        "    return code\n",
        "  except:\n",
        "    print(f\"Error submission did not find code {LINK}\\n\")\n",
        "    return \"\"\n",
        "#code = extract_code_from_submission(soup, Link1)"
      ],
      "metadata": {
        "id": "6aJiw_ZTTdbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(code)"
      ],
      "metadata": {
        "id": "LBScBTXmVASN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.multiarray import empty\n",
        "from bs4.element import NavigableString\n",
        "def extract_text_mathlb_from_problem(position):\n",
        "  data = \"\"\n",
        "  math_pos = []\n",
        "  try:\n",
        "    if len(position.contents) > 1:\n",
        "      for child in position.children:\n",
        "          X , math_pos1 = extract_text_mathlb_from_problem(child)\n",
        "          if child.name == \"div\" or child.name == \"p\":\n",
        "              data += \"\\n\"\n",
        "              math_pos.extend([0,0])\n",
        "          else:\n",
        "              data += \" \"\n",
        "              math_pos.extend([0])\n",
        "          data += X\n",
        "          math_pos.extend(math_pos1)\n",
        "    else:\n",
        "      if position.name == 'span' and position.get('class') == ['MathJax']:\n",
        "          data = position.get('data-mathml')\n",
        "\n",
        "          math_pos.extend([1 for i in range(len(data))])\n",
        "      else:\n",
        "          data = position.get_text(strip=False)\n",
        "          math_pos.extend([0 for i in range(len(data))])\n",
        "  except:\n",
        "    if str(position).strip():\n",
        "      data = str(position).strip()\n",
        "      math_pos.extend([0 for i in range(len(data))])\n",
        "  return data , math_pos"
      ],
      "metadata": {
        "id": "cMBpWER6in7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Link1= \"https://codeforces.com/contest/1370/problem/F1\"\n",
        "page = requests.get(Link1)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "problem_statement = soup.find(class_='problem-statement')\n",
        "Data , pos = extract_text_mathlb_from_problem(problem_statement)"
      ],
      "metadata": {
        "id": "W3mnJVLu9cGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Data)"
      ],
      "metadata": {
        "id": "ky9JDR0g7IuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Links)"
      ],
      "metadata": {
        "id": "hHYo52JV9UYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataSet = []"
      ],
      "metadata": {
        "id": "SDdI0l4wlSiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import requests\n",
        "import traceback\n",
        "from bs4 import BeautifulSoup\n",
        "# Specify the timeout value in seconds\n",
        "import threading\n",
        "\n",
        "\n",
        "\n",
        "j = 0\n",
        "problems_num1 = 0\n",
        "problems_num2 = 0\n",
        "status_num1 = 0\n",
        "submissions_num1 = 0\n",
        "lock = threading.Lock()\n",
        "lock1 = threading.Lock()\n",
        "lock2 = threading.Lock()\n",
        "lock3 = threading.Lock()\n",
        "def process_link(link):\n",
        "    problem_link = link[0]\n",
        "    status_link = link[1]\n",
        "    try:\n",
        "      lock.acquire()\n",
        "      try:\n",
        "        page = requests.get(problem_link ,timeout=1)\n",
        "      finally:\n",
        "        lock.release()\n",
        "      global problems_num1\n",
        "      global  problems_num2\n",
        "      global submissions_num1\n",
        "      global status_num1\n",
        "      global j\n",
        "      global DataSet\n",
        "      problems_num1 += 1\n",
        "      if page.status_code != 200:\n",
        "        print(f\"Error - could not access to problem link: {problem_link}\",\"\\n\")\n",
        "        problems_num2 += 1\n",
        "        return\n",
        "\n",
        "      print(f\"Problem {problems_num1} , {problems_num2} , {problem_link}\", page.status_code,\"\\n\")\n",
        "      soup = BeautifulSoup(page.content, 'html.parser')\n",
        "      problem_statement = soup.find(class_='problem-statement')\n",
        "      problem_data, pos = extract_text_mathlb_from_problem(problem_statement)\n",
        "      try:\n",
        "        lock1.acquire()\n",
        "        try:\n",
        "          submissions_links = extract_submissions_links_from_all_status(status_link)\n",
        "        finally:\n",
        "         lock1.release()\n",
        "        # Critical section: perform operations while the lock is held\n",
        "        print(status_link , submissions_links,\"\\n\")\n",
        "        print(problem_link,len(submissions_links),\"\\n\")\n",
        "        for submission in submissions_links:\n",
        "          try:\n",
        "            page = requests.get(submission[0] ,timeout=timeout_seconds)\n",
        "            if page.status_code != 200:\n",
        "              print(f\"Error - could not access to submission link: {status_link}\\n\")\n",
        "              submissions_num1 += 1\n",
        "              continue\n",
        "            print(f\"Submission {submission[0]} , f{submissions_num1}\",page.status_code,\"\\n\")\n",
        "            soup = BeautifulSoup(page.content, 'html.parser')\n",
        "            code = extract_code_from_submission(soup, submission[0])\n",
        "            if code == \" \":\n",
        "              submissions_num1+=1\n",
        "              continue\n",
        "            DATA_FORM = {\n",
        "                'problem_statement': problem_data,\n",
        "                'solution': code,\n",
        "                'solution_link': submission[0],\n",
        "                'solution_id': submission[0],\n",
        "                'problem_link': problem_link\n",
        "            }\n",
        "            lock3.acquire()\n",
        "            try:\n",
        "              DataSet.append(DATA_FORM)\n",
        "            finally:\n",
        "              lock3.release()\n",
        "            j += 1\n",
        "            print(j, \" number of submissions till now\\n\")\n",
        "          except Exception as e:\n",
        "            traceback.print_exc()\n",
        "            print(f\"could not access to the submission {submission[0]}\\n\")\n",
        "      except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        print(f\"could not access to the status_link {status_link}\\n\")\n",
        "    except Exception as e:\n",
        "      traceback.print_exc()\n",
        "      print(f\"could not access to the problem link {problem_link}\\n\")\n",
        "\n",
        "def make_json(Links):\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=7) as executor:\n",
        "        executor.map(process_link, Links)\n",
        "\n",
        "make_json(Links[1000:2000])"
      ],
      "metadata": {
        "id": "33vRCCUzp8eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"key_to_check = \"solution\"\n",
        "\n",
        "unique_values = set()\n",
        "\n",
        "for item in DataSet:\n",
        "    print(item[\"solution_id\"],item[\"problem_link\"])\n",
        "    value = item[key_to_check]\n",
        "    if value is not None:\n",
        "        unique_values.add(value)\n",
        "print(len(unique_values))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UKgX6GB-HgIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = 'output1to2.csv'\n",
        "\n",
        "# Extract the keys from the first dictionary in the list\n",
        "keys = DataSet[0].keys()\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=keys)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write each dictionary as a CSV row\n",
        "    writer.writerows(DataSet)\n",
        "\n",
        "print(f'CSV file \"{output_file}\" created successfully.')"
      ],
      "metadata": {
        "id": "ocvGnITPBsmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n"
      ],
      "metadata": {
        "id": "c-tjPS39wbu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip codeforces-v2-1to2.zip /content/output1to2.csv"
      ],
      "metadata": {
        "id": "cPPQQKnQ8VNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/codeforces-v2-1to2.zip /content/drive/MyDrive/codeforces-v2-1to2.zip"
      ],
      "metadata": {
        "id": "Dcjn9Rmz7gdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fq3symok7kl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}